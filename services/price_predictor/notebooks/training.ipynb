{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add autoreload magic\n",
    "import pandas as pd\n",
    "from loguru import logger\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global parameters\n",
    "feature_view_name = 'ohlc_feature_view'\n",
    "feature_view_version = 1\n",
    "ohlc_window_sec = 60\n",
    "product_id = 'BTC/USD'\n",
    "last_n_days_to_fetch_from_store = 90\n",
    "last_n_days_to_test_model = 7\n",
    "discretization_thresholds = [-0.0001, 0.0001]\n",
    "prediction_window_sec = 60*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HOPSWORKS_API_KEY'] = <API_KEY>\n",
    "os.environ['HOPSWORKS_PROJECT_NAME'] = <PROJECT_NAME>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the path three levels up from the current script/notebook\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir, os.pardir, os.pardir))\n",
    "\n",
    "# Add this directory to sys.path\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/897173\n",
      "2024-08-09 02:17:55,967 WARNING: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "\n",
      "2024-08-09 02:17:55,968 WARNING: using legacy validation callback\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-09 02:17:56.332\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mFetching OHLC data from the feature store\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (2.29s) \n"
     ]
    }
   ],
   "source": [
    "from tools.tools.ohlc_data_reader import OhlcDataReader\n",
    "\n",
    "\n",
    "ohlc_data_reader = OhlcDataReader(\n",
    "    ohlc_window_sec=ohlc_window_sec,\n",
    "    feature_view_name=feature_view_name,\n",
    "    feature_view_version=feature_view_version,\n",
    ")\n",
    "\n",
    "logger.info('Fetching OHLC data from the feature store')\n",
    "\n",
    "ohlc_data = ohlc_data_reader.read_from_offline_store(\n",
    "    product_id=product_id,\n",
    "    last_n_days=last_n_days_to_fetch_from_store,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column to ohlc_data with a human-readable data, using\n",
    "# the ohlc_data['timestamp'] column in milliseconds\n",
    "ohlc_data['datetime'] = pd.to_datetime(ohlc_data['timestamp'], unit='ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-09 02:21:40.124\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mSplitting the data into training and testing\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Get the path one level up from the current script/notebook\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "\n",
    "# Add this directory to sys.path\n",
    "sys.path.append(parent_dir)\n",
    "from src.training import split_train_test\n",
    "\n",
    "# Step 2\n",
    "# Split the data into training and testing using a cutoff date\n",
    "logger.info('Splitting the data into training and testing')\n",
    "ohlc_train, ohlc_test = split_train_test(\n",
    "    ohlc_data=ohlc_data,\n",
    "    last_n_days_to_test_model=last_n_days_to_test_model,\n",
    ")\n",
    "\n",
    "# print(ohlc_train.head())\n",
    "# print(ohlc_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-09 02:22:25.377\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mInterpolating missing candles for training data\u001b[0m\n",
      "\u001b[32m2024-08-09 02:22:25.718\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m8\u001b[0m - \u001b[1mInterpolating missing candles for testing data\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from src.training import interpolate_missing_candles\n",
    "\n",
    "# Step 3\n",
    "# Preprocess the data for training and for testing\n",
    "# Interpolate missing candles\n",
    "logger.info('Interpolating missing candles for training data')\n",
    "ohlc_train = interpolate_missing_candles(ohlc_train, ohlc_window_sec)\n",
    "logger.info('Interpolating missing candles for testing data')\n",
    "ohlc_test = interpolate_missing_candles(ohlc_test, ohlc_window_sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-09 02:28:30.192\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m5\u001b[0m - \u001b[1mCreating the target metric\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from src.data_preprocessing import create_target_metric\n",
    "\n",
    "# Step 4\n",
    "# Create the target metric as a new column in our dataframe for training and testing\n",
    "logger.info('Creating the target metric')\n",
    "ohlc_train = create_target_metric(\n",
    "    ohlc_train,\n",
    "    ohlc_window_sec,\n",
    "    #discretization_thresholds,\n",
    "    prediction_window_sec,\n",
    ")\n",
    "ohlc_test = create_target_metric(\n",
    "    ohlc_test,\n",
    "    ohlc_window_sec,\n",
    "    #discretization_thresholds,\n",
    "    prediction_window_sec,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-09 02:29:12.610\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m2\u001b[0m - \u001b[1mDistribution of the target in the training data\u001b[0m\n",
      "\u001b[32m2024-08-09 02:29:12.655\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m3\u001b[0m - \u001b[34m\u001b[1mtarget\n",
      " 0.000000    5079\n",
      " 0.000001      22\n",
      "-0.000001      20\n",
      " 0.000002      19\n",
      " 0.000001      17\n",
      "             ... \n",
      "-0.001522       1\n",
      "-0.001722       1\n",
      "-0.002219       1\n",
      "-0.000845       1\n",
      "-0.004413       1\n",
      "Name: count, Length: 74295, dtype: int64\u001b[0m\n",
      "\u001b[32m2024-08-09 02:29:12.687\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m4\u001b[0m - \u001b[1mDistribution of the target in the testing data\u001b[0m\n",
      "\u001b[32m2024-08-09 02:29:12.692\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m5\u001b[0m - \u001b[34m\u001b[1mtarget\n",
      " 0.000000    38\n",
      " 0.001775     5\n",
      "-0.000327     3\n",
      " 0.000867     2\n",
      "-0.000655     2\n",
      "-0.001224     2\n",
      "-0.001364     2\n",
      "-0.000861     2\n",
      " 0.003162     2\n",
      "-0.002193     1\n",
      "-0.001540     1\n",
      "-0.002369     1\n",
      "-0.001800     1\n",
      "-0.002333     1\n",
      "Name: count, dtype: int64\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Plot distribution of the target\n",
    "logger.info('Distribution of the target in the training data')\n",
    "logger.debug(ohlc_train['target'].value_counts())\n",
    "logger.info('Distribution of the target in the testing data')\n",
    "logger.debug(ohlc_test['target'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = ohlc_test.drop(columns=['target'])\n",
    "y_test = ohlc_test['target']\n",
    "X_train = ohlc_train.drop(columns=['target'])\n",
    "y_train = ohlc_train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** TEST DATA ******\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of continuous and binary targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m****** TEST DATA ******\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Compute accuracy using scikit-learn\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test_predictions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy of the model on test data: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClassification report of the model:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:231\u001b[0m, in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    229\u001b[0m xp, _, device \u001b[38;5;241m=\u001b[39m get_namespace_and_device(y_true, y_pred, sample_weight)\n\u001b[0;32m    230\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[1;32m--> 231\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:112\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m    109\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 112\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    113\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    114\u001b[0m             type_true, type_pred\n\u001b[0;32m    115\u001b[0m         )\n\u001b[0;32m    116\u001b[0m     )\n\u001b[0;32m    118\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m    119\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of continuous and binary targets"
     ]
    }
   ],
   "source": [
    "from src.baseline_model import BaselineModel\n",
    "\n",
    "# create model\n",
    "model = BaselineModel(\n",
    "    n_candles_into_future=prediction_window_sec // ohlc_window_sec,\n",
    "    #discretization_thresholds=discretization_thresholds,\n",
    ")\n",
    "\n",
    "# generate predictions\n",
    "y_test_predictions = model.predict(X_test)\n",
    "\n",
    "# evalute our dummy model\n",
    "# Let's evaluate the model. It is a classifier with 3 classes\n",
    "\n",
    "print('****** TEST DATA ******')\n",
    "# Compute accuracy using scikit-learn\n",
    "accuracy = accuracy_score(y_test, y_test_predictions)\n",
    "print(f'Accuracy of the model on test data: {accuracy}')\n",
    "\n",
    "print(f'Classification report of the model:')\n",
    "print(classification_report(y_test, y_test_predictions))\n",
    "\n",
    "# generate predictions\n",
    "print('****** TRAINING DATA ******')\n",
    "y_train_predictions = model.predict(X_train)\n",
    "accuracy = accuracy_score(y_train, y_train_predictions)\n",
    "print(f'Accuracy of the model: {accuracy}')\n",
    "\n",
    "print(f'Classification report of the model:')\n",
    "print(classification_report(y_train, y_train_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
